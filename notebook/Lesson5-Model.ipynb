{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "knowing-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-kidney",
   "metadata": {},
   "source": [
    "## Lesson 5 - Model\n",
    " - 이번 실습 자료에서는 강의시간에 다루었던 파이토치 모델을 정의하는 방법에 대해 실습하겠습니다.\n",
    " - 파이토치 모델은 기본적으로 `nn.Module` 클래스를 상속하여 사용합니다.\n",
    "     - [공식문서](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)에 따르면 `nn.Module` 은 다음과 같은 기능을 합니다\n",
    "     ```\n",
    "     Base class for all neural network modules.\n",
    "     Your models should also subclass this class.\n",
    "     Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes:\n",
    "     ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "absolute-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "detailed-dylan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-mineral",
   "metadata": {},
   "source": [
    "### 모델 디버깅\n",
    " - 파이토치 모델들은 다음과 같읕 방법들을 통해 파라미터를 눈으로 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spoken-frank",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight         - size: torch.Size([3, 1, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.2272,  0.0789, -0.2015],\n",
      "          [-0.2786,  0.2202,  0.2443],\n",
      "          [ 0.2430,  0.2122, -0.0559]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3066,  0.1874, -0.2951],\n",
      "          [ 0.0564,  0.2574, -0.3310],\n",
      "          [ 0.2893, -0.2795, -0.1368]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2020, -0.0426, -0.3137],\n",
      "          [ 0.2169, -0.1548, -0.0449],\n",
      "          [-0.0353,  0.3062,  0.2574]]]], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "conv1.bias           - size: torch.Size([3])\n",
      "Parameter containing:\n",
      "tensor([-0.2309, -0.2201, -0.0415], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "bn1.weight           - size: torch.Size([3])\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "bn1.bias             - size: torch.Size([3])\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "conv2.weight         - size: torch.Size([5, 3, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[-0.1532, -0.1503, -0.0547],\n",
      "          [ 0.1081, -0.1405, -0.1195],\n",
      "          [ 0.0319,  0.0622, -0.0486]],\n",
      "\n",
      "         [[ 0.1173,  0.1410, -0.1477],\n",
      "          [ 0.1610,  0.0433, -0.1057],\n",
      "          [-0.1841, -0.0650,  0.1596]],\n",
      "\n",
      "         [[ 0.0709, -0.1501,  0.0574],\n",
      "          [ 0.1436, -0.1189,  0.1112],\n",
      "          [ 0.1539,  0.1797, -0.0013]]],\n",
      "\n",
      "\n",
      "        [[[-0.1392, -0.0890,  0.1715],\n",
      "          [ 0.1167,  0.0074, -0.0866],\n",
      "          [-0.1127, -0.0581,  0.0300]],\n",
      "\n",
      "         [[ 0.1866, -0.0967,  0.1391],\n",
      "          [ 0.1323, -0.0169,  0.0520],\n",
      "          [ 0.0117,  0.0017,  0.0266]],\n",
      "\n",
      "         [[ 0.1499,  0.1756,  0.0488],\n",
      "          [-0.1169, -0.0094,  0.0382],\n",
      "          [-0.1231,  0.0995, -0.1037]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1276, -0.0624, -0.1026],\n",
      "          [ 0.0028, -0.1125, -0.0240],\n",
      "          [-0.1835,  0.1239,  0.1570]],\n",
      "\n",
      "         [[-0.0610,  0.1416,  0.0693],\n",
      "          [ 0.1760, -0.0748, -0.1729],\n",
      "          [-0.1202, -0.1226,  0.0983]],\n",
      "\n",
      "         [[-0.0388, -0.1580,  0.1113],\n",
      "          [-0.0190,  0.0716,  0.1006],\n",
      "          [-0.0461, -0.1193, -0.0745]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0946,  0.0924,  0.0329],\n",
      "          [ 0.1674,  0.0905,  0.0482],\n",
      "          [-0.0609,  0.1402, -0.1191]],\n",
      "\n",
      "         [[ 0.1165, -0.1441, -0.0624],\n",
      "          [-0.1368,  0.1098,  0.0834],\n",
      "          [ 0.1821,  0.0943,  0.1592]],\n",
      "\n",
      "         [[-0.1835, -0.1243, -0.1594],\n",
      "          [ 0.0762, -0.0427,  0.1550],\n",
      "          [-0.0632,  0.0542,  0.0534]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1367,  0.0609,  0.0218],\n",
      "          [-0.1589,  0.0978,  0.1136],\n",
      "          [-0.0294,  0.0494, -0.1924]],\n",
      "\n",
      "         [[-0.0857,  0.0571,  0.0958],\n",
      "          [-0.0060, -0.0768, -0.0377],\n",
      "          [ 0.0298,  0.0505, -0.1350]],\n",
      "\n",
      "         [[ 0.0730, -0.0414,  0.0481],\n",
      "          [-0.1058, -0.0291, -0.0554],\n",
      "          [-0.1803,  0.1053,  0.0289]]]], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. using named_parameters()\n",
    "for param, weight in model.named_parameters():\n",
    "    print(f\"{param:20} - size: {weight.size()}\")\n",
    "    print(weight)\n",
    "    print(\"-\" * 100)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "turkish-wisdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.2272,  0.0789, -0.2015],\n",
      "          [-0.2786,  0.2202,  0.2443],\n",
      "          [ 0.2430,  0.2122, -0.0559]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3066,  0.1874, -0.2951],\n",
      "          [ 0.0564,  0.2574, -0.3310],\n",
      "          [ 0.2893, -0.2795, -0.1368]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2020, -0.0426, -0.3137],\n",
      "          [ 0.2169, -0.1548, -0.0449],\n",
      "          [-0.0353,  0.3062,  0.2574]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2309, -0.2201, -0.0415], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 2. directly access with member variable\n",
    "print(model.conv1.weight)\n",
    "print(model.conv1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-patient",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "impressive-smile",
   "metadata": {},
   "source": [
    "### 학습된 모델 저장하기\n",
    " - `torch.save(model.state_dict(), save_path)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "august-austin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saving success at ./runs/best.pth\n",
      "Saved models : ['adam', 'noage-vgg19-noaug', 'vgg19', 'no_aug', 'vgg19-noaug', 'baseline', 'noage-vgg19-coolaug', 'best.pth', 'cool_aug', 'vgg19-aug']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "save_folder = \"./runs/\"\n",
    "save_path = os.path.join(save_folder, \"best.pth\")   # ./runs/best.pth\n",
    "os.makedirs(save_folder, exist_ok=True)  \n",
    "\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saving success at {save_path}\")\n",
    "print(f\"Saved models : {os.listdir(save_folder)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-toolbox",
   "metadata": {},
   "source": [
    "### 저장된 모델 불러오기\n",
    " - model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "impressed-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loading success from ./runs/best.pth\n"
     ]
    }
   ],
   "source": [
    "new_model = Model()\n",
    "new_model.load_state_dict(torch.load(save_path))\n",
    "print(f\"Model loading success from {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-cylinder",
   "metadata": {},
   "source": [
    "#### 저장된 모델이 잘 불러와졌는지 확인해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "promising-jesus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter conv1.weight    from trained model and loaded model is equal? -> True\n",
      "parameter conv1.bias      from trained model and loaded model is equal? -> True\n",
      "parameter bn1.weight      from trained model and loaded model is equal? -> True\n",
      "parameter bn1.bias        from trained model and loaded model is equal? -> True\n",
      "parameter conv2.weight    from trained model and loaded model is equal? -> True\n"
     ]
    }
   ],
   "source": [
    "for (name, trained_weight), (_, saved_weight) in zip(model.named_parameters(), new_model.named_parameters()):\n",
    "    is_equal = torch.equal(trained_weight, saved_weight)\n",
    "    print(f\"parameter {name:15} from trained model and loaded model is equal? -> {is_equal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-headline",
   "metadata": {},
   "source": [
    "#### state_dict() 이 무엇인가요?\n",
    " - 모델의 저장과 로딩에 `state_dict()` 을 사용하는데, 기능이 무엇인가요?\n",
    " - 기본적으로 위에서 살펴본 `.named_parameters()` 와 매우 유사합니다\n",
    " - model parameter 를 Key 로 가지고, model weights 를 Value 로 가지는 파이썬 딕셔너리일 뿐입니다. \n",
    "   (정확한 Type 은 파이썬 내장 라이브러리 collections.OrderDict 입니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "social-stamp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight         - size: torch.Size([3, 1, 3, 3])\n",
      "tensor([[[[ 0.2272,  0.0789, -0.2015],\n",
      "          [-0.2786,  0.2202,  0.2443],\n",
      "          [ 0.2430,  0.2122, -0.0559]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3066,  0.1874, -0.2951],\n",
      "          [ 0.0564,  0.2574, -0.3310],\n",
      "          [ 0.2893, -0.2795, -0.1368]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2020, -0.0426, -0.3137],\n",
      "          [ 0.2169, -0.1548, -0.0449],\n",
      "          [-0.0353,  0.3062,  0.2574]]]])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "conv1.bias           - size: torch.Size([3])\n",
      "tensor([-0.2309, -0.2201, -0.0415])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.weight           - size: torch.Size([3])\n",
      "tensor([1., 1., 1.])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.bias             - size: torch.Size([3])\n",
      "tensor([0., 0., 0.])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.running_mean     - size: torch.Size([3])\n",
      "tensor([0., 0., 0.])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.running_var      - size: torch.Size([3])\n",
      "tensor([1., 1., 1.])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.num_batches_tracked - size: torch.Size([])\n",
      "tensor(0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "conv2.weight         - size: torch.Size([5, 3, 3, 3])\n",
      "tensor([[[[-0.1532, -0.1503, -0.0547],\n",
      "          [ 0.1081, -0.1405, -0.1195],\n",
      "          [ 0.0319,  0.0622, -0.0486]],\n",
      "\n",
      "         [[ 0.1173,  0.1410, -0.1477],\n",
      "          [ 0.1610,  0.0433, -0.1057],\n",
      "          [-0.1841, -0.0650,  0.1596]],\n",
      "\n",
      "         [[ 0.0709, -0.1501,  0.0574],\n",
      "          [ 0.1436, -0.1189,  0.1112],\n",
      "          [ 0.1539,  0.1797, -0.0013]]],\n",
      "\n",
      "\n",
      "        [[[-0.1392, -0.0890,  0.1715],\n",
      "          [ 0.1167,  0.0074, -0.0866],\n",
      "          [-0.1127, -0.0581,  0.0300]],\n",
      "\n",
      "         [[ 0.1866, -0.0967,  0.1391],\n",
      "          [ 0.1323, -0.0169,  0.0520],\n",
      "          [ 0.0117,  0.0017,  0.0266]],\n",
      "\n",
      "         [[ 0.1499,  0.1756,  0.0488],\n",
      "          [-0.1169, -0.0094,  0.0382],\n",
      "          [-0.1231,  0.0995, -0.1037]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1276, -0.0624, -0.1026],\n",
      "          [ 0.0028, -0.1125, -0.0240],\n",
      "          [-0.1835,  0.1239,  0.1570]],\n",
      "\n",
      "         [[-0.0610,  0.1416,  0.0693],\n",
      "          [ 0.1760, -0.0748, -0.1729],\n",
      "          [-0.1202, -0.1226,  0.0983]],\n",
      "\n",
      "         [[-0.0388, -0.1580,  0.1113],\n",
      "          [-0.0190,  0.0716,  0.1006],\n",
      "          [-0.0461, -0.1193, -0.0745]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0946,  0.0924,  0.0329],\n",
      "          [ 0.1674,  0.0905,  0.0482],\n",
      "          [-0.0609,  0.1402, -0.1191]],\n",
      "\n",
      "         [[ 0.1165, -0.1441, -0.0624],\n",
      "          [-0.1368,  0.1098,  0.0834],\n",
      "          [ 0.1821,  0.0943,  0.1592]],\n",
      "\n",
      "         [[-0.1835, -0.1243, -0.1594],\n",
      "          [ 0.0762, -0.0427,  0.1550],\n",
      "          [-0.0632,  0.0542,  0.0534]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1367,  0.0609,  0.0218],\n",
      "          [-0.1589,  0.0978,  0.1136],\n",
      "          [-0.0294,  0.0494, -0.1924]],\n",
      "\n",
      "         [[-0.0857,  0.0571,  0.0958],\n",
      "          [-0.0060, -0.0768, -0.0377],\n",
      "          [ 0.0298,  0.0505, -0.1350]],\n",
      "\n",
      "         [[ 0.0730, -0.0414,  0.0481],\n",
      "          [-0.1058, -0.0291, -0.0554],\n",
      "          [-0.1803,  0.1053,  0.0289]]]])\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for param, weight in model.state_dict().items():\n",
    "    print(f\"{param:20} - size: {weight.size()}\")\n",
    "    print(weight)\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "handed-stomach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.state_dict() type is : <class 'collections.OrderedDict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "print(f\"model.state_dict() type is : {type(model.state_dict())}\")\n",
    "type(model.state_dict()) == OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-catalog",
   "metadata": {},
   "source": [
    "#### `named_parameters()` 을 안쓰고 `state_dict()` 을 사용하는 이유가 무언인가요? (둘이 뭐가 다른가요)\n",
    " - `named_parameters()` : returns only parameters\n",
    " - `state_dict()`: returns both parameters and buffers (e.g. BN runnin_mean, running_var)\n",
    " \n",
    " [Reference](https://stackoverflow.com/a/54747245)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "completed-delaware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1.weight', 'conv1.bias', 'bn1.weight', 'bn1.bias', 'conv2.weight']\n",
      "\n",
      "['conv1.weight',\n",
      " 'conv1.bias',\n",
      " 'bn1.weight',\n",
      " 'bn1.bias',\n",
      " 'bn1.running_mean',\n",
      " 'bn1.running_var',\n",
      " 'bn1.num_batches_tracked',\n",
      " 'conv2.weight']\n"
     ]
    }
   ],
   "source": [
    "pprint([name for (name, param) in model.named_parameters()])  # named_parameters() : returns only parameters\n",
    "print()\n",
    "pprint(list(model.state_dict().keys()))  # state_dict(): retuns both parameters and buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-scheme",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "italic-solid",
   "metadata": {},
   "source": [
    "### CPU vs GPU\n",
    " - DL 모델은 다양한 프로세서(CPU, GPU, TPU) 를 사용하여 학습을 할 수 있습니다.\n",
    " - 따라서, 특정 프로세서에서 학습을 진행하고 싶은 경우 명시적으로 지정해주어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-bruce",
   "metadata": {},
   "source": [
    "#### cpu()\n",
    "Moves all model parameters and buffers to the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compound-implementation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n"
     ]
    }
   ],
   "source": [
    "model.cpu()\n",
    "for weight in model.parameters():\n",
    "    print(f\"model device: {weight.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-monster",
   "metadata": {},
   "source": [
    "#### cuda()\n",
    "Moves all model parameters and buffers to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "assigned-glasgow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "for weight in model.parameters():\n",
    "    print(f\"model device: {weight.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-oxide",
   "metadata": {},
   "source": [
    "#### to()\n",
    "Moves and/or casts the parameters and buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "korean-peace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set model device to cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "\n",
      "Set model device to cuda\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device_options = ['cpu', 'cuda']\n",
    "for device_option in device_options:\n",
    "    device = torch.device(device_option)\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"Set model device to {device_option}\")\n",
    "    for weight in model.parameters():\n",
    "        print(f\"model device: {weight.device}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-resolution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "reserved-introduction",
   "metadata": {},
   "source": [
    "### forward\n",
    " - nn.Module 을 상속한 객체를 직접 호출할 때 수행하는 연산을 정의합니다.\n",
    " - Defines the computation performed at every call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "political-dragon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output: torch.Size([1, 5, 8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.4035, 0.0000, 0.0000, 0.0000, 0.1073, 0.0000, 0.0000, 0.1513],\n",
       "          [0.0000, 0.0000, 0.0910, 0.0000, 0.0000, 0.0000, 0.2804, 0.9995],\n",
       "          [0.6133, 0.0437, 0.0963, 0.0345, 0.0000, 0.2947, 0.6510, 0.6089],\n",
       "          [0.5390, 0.2805, 0.2361, 0.0484, 0.0489, 0.2519, 0.0501, 0.1270],\n",
       "          [0.8291, 0.2399, 0.2885, 0.3394, 0.2485, 0.0000, 0.0000, 0.2624],\n",
       "          [0.0000, 0.0000, 0.3346, 0.0113, 0.0000, 0.0000, 0.3053, 0.0000],\n",
       "          [0.2040, 0.0000, 0.0000, 0.1888, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.4480, 0.3294, 0.0000, 0.0039, 0.4005, 0.1434, 0.0000]],\n",
       "\n",
       "         [[0.6537, 0.7131, 0.0352, 0.0000, 0.4047, 0.5929, 0.2717, 0.0000],\n",
       "          [0.0521, 0.1169, 0.1576, 0.6334, 0.2149, 0.0954, 0.0000, 0.3575],\n",
       "          [0.0000, 0.0578, 0.0000, 0.0702, 0.3985, 0.0101, 0.5599, 0.0000],\n",
       "          [0.1466, 0.0941, 0.0000, 0.0343, 0.0000, 0.1361, 0.0640, 0.8798],\n",
       "          [0.9604, 0.0000, 0.0000, 0.1020, 0.2218, 0.0105, 0.5853, 0.0000],\n",
       "          [0.0000, 0.7115, 0.4553, 0.0000, 0.0000, 0.5136, 0.1645, 0.1995],\n",
       "          [0.8430, 0.0000, 0.2476, 0.9175, 0.3081, 0.0000, 0.8759, 0.4628],\n",
       "          [0.0000, 0.6863, 0.0000, 0.2844, 0.3014, 0.4781, 0.5208, 0.0000]],\n",
       "\n",
       "         [[0.2573, 0.0000, 0.0000, 0.5118, 0.0000, 0.0000, 0.0000, 0.2167],\n",
       "          [0.0000, 0.0000, 0.0544, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.1191, 0.0000, 0.0164, 0.5314, 0.4590, 0.1988],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.1317, 0.0000, 0.0000, 0.0000],\n",
       "          [0.1742, 0.1611, 0.0000, 0.2825, 0.4244, 0.0000, 0.0000, 0.3965],\n",
       "          [0.0000, 0.0000, 0.4048, 0.0000, 0.0000, 0.0000, 0.5648, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3735, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.1460, 0.0000, 0.0000, 0.1027, 0.1573, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.1585, 0.2599, 0.1787, 0.5677, 0.8183, 0.8738, 0.0317],\n",
       "          [0.4537, 0.0000, 0.0000, 0.0000, 0.2043, 0.8933, 0.1482, 0.2442],\n",
       "          [0.1245, 0.0410, 0.0000, 0.2446, 0.3180, 0.0000, 0.3844, 0.0000],\n",
       "          [0.0826, 0.3335, 0.0000, 0.1561, 0.0000, 0.1197, 0.0000, 0.2304],\n",
       "          [0.4729, 0.0000, 0.5397, 0.0000, 0.5100, 0.0000, 0.4846, 0.6353],\n",
       "          [0.0000, 0.7122, 0.1117, 0.5005, 0.3991, 0.7434, 0.3287, 0.3363],\n",
       "          [0.6293, 0.0000, 0.4257, 0.3845, 0.7322, 0.2730, 0.2806, 0.2741],\n",
       "          [0.2830, 0.5866, 0.0000, 0.7285, 0.2372, 0.0171, 0.2807, 0.1921]],\n",
       "\n",
       "         [[0.0000, 0.0050, 0.4586, 0.6647, 0.0000, 0.0000, 0.2949, 0.2367],\n",
       "          [0.0000, 0.0178, 0.0000, 0.0000, 0.2268, 0.2706, 0.0717, 0.0000],\n",
       "          [0.0000, 0.0000, 0.1166, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0965, 0.0000, 0.0225, 0.0000],\n",
       "          [0.0000, 0.0420, 0.0310, 0.0000, 0.0000, 0.1688, 0.0000, 0.2436],\n",
       "          [0.3686, 0.0000, 0.0000, 0.0023, 0.0875, 0.0000, 0.0049, 0.1743],\n",
       "          [0.0000, 0.3060, 0.0694, 0.0000, 0.0000, 0.3794, 0.0000, 0.0000],\n",
       "          [0.4526, 0.0000, 0.0000, 0.1319, 0.3148, 0.0000, 0.0309, 0.2294]]]],\n",
       "       device='cuda:0', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 1, 12, 12).to(device)\n",
    "model.to(device)\n",
    "output = model(dummy_input)\n",
    "print(f\"model output: {output.size()}\")\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-peninsula",
   "metadata": {},
   "source": [
    "#### Cautions\n",
    " - 모델과 인풋의 device 는 반드시 같아야 합니다.\n",
    " - 그렇지 않으면 (Runtime) Error 가 발생합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "utility-professor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output: torch.Size([1, 5, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "cpu_device = torch.device('cpu')\n",
    "gpu_device = torch.device('cuda')\n",
    "\n",
    "# device is same\n",
    "dummy_input = dummy_input.to(gpu_device)\n",
    "model.to(gpu_device)\n",
    "output = model(dummy_input)  # Fine \n",
    "print(f\"model output: {output.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "desperate-tulsa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-52d7e79efd68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# device is different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# raise Error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"model output: {output.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-df9735abf4b2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward"
     ]
    }
   ],
   "source": [
    "dummy_input = dummy_input.to(cpu_device)\n",
    "model.to(gpu_device)\n",
    "\n",
    "# device is different\n",
    "# RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\n",
    "output = model(dummy_input)  # raise Error\n",
    "print(f\"model output: {output.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-exclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "operational-american",
   "metadata": {},
   "source": [
    "### requires_grad()\n",
    " - autograd 가 해당 모델의 연산을 기록할지를 결정합니다\n",
    " - false 일 시, 수행하는 연산을 기록하지 않고 따라서 역전파가 되지 않아 학습에서 제외됩니다.\n",
    " - Change if autograd should record operations on parameters in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "supposed-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param conv1.weight    required gradient? -> False\n",
      "param conv1.bias      required gradient? -> False\n",
      "param bn1.weight      required gradient? -> False\n",
      "param bn1.bias        required gradient? -> False\n",
      "param conv2.weight    required gradient? -> False\n"
     ]
    }
   ],
   "source": [
    "# requires_grad = False\n",
    "model.requires_grad_(requires_grad=False)\n",
    "for param, weight in model.named_parameters():\n",
    "    print(f\"param {param:15} required gradient? -> {weight.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "absent-strip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param conv1.weight    required gradient? -> True\n",
      "param conv1.bias      required gradient? -> True\n",
      "param bn1.weight      required gradient? -> True\n",
      "param bn1.bias        required gradient? -> True\n",
      "param conv2.weight    required gradient? -> True\n"
     ]
    }
   ],
   "source": [
    "# requires_grad = True\n",
    "model.requires_grad_(requires_grad=True)\n",
    "for param, weight in model.named_parameters():\n",
    "    print(f\"param {param:15} required gradient? -> {weight.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-fight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-aspect",
   "metadata": {},
   "source": [
    "### train(), eval()\n",
    " - 모델을 training(evaluation) 모드로 전환합니다.\n",
    " - training 과 evaluation 이 다르게 작용하는 모듈들(Dropout, BatchNorm) 에 영향을 줍니다.\n",
    " - 학습 단계에서는 training 모드로, 인퍼런스 단계에서는 eval 모드로 전환해주어야 합니다.\n",
    " - [아래](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/batchnorm.py#L111-L118)는 BatchNorm2d 의 파이토치 구현입니다. `self.training=True` 일 경우에만, `running_mean`, `running_var` 을 tracking 합니다.\n",
    " \n",
    "```\n",
    "if self.training and self.track_running_stats:\n",
    "    # TODO: if statement only here to tell the jit to skip emitting this when it is None\n",
    "    if self.num_batches_tracked is not None:\n",
    "        self.num_batches_tracked = self.num_batches_tracked + 1\n",
    "        if self.momentum is None:  # use cumulative moving average\n",
    "            exponential_average_factor = 1.0 / float(self.num_batches_tracked)\n",
    "        else:  # use exponential moving average\n",
    "            exponential_average_factor = self.momentum\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nonprofit-lotus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.bn1.training: True\n"
     ]
    }
   ],
   "source": [
    "model.train()  # set model to train mode\n",
    "print(f\"model.bn1.training: {model.bn1.training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "worse-issue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.bn1.training: False\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # set model to eval mode\n",
    "print(f\"model.bn1.training: {model.bn1.training}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-webster",
   "metadata": {},
   "source": [
    "### 파이토치 공식 문서에서 nn.Module 에 관한 더 많은 정보를 얻을 수 있습니다.\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "\n",
    "궁금증이 생기면 공식 문서를 참고하는걸 강력 추천합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
