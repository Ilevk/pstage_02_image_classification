{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "knowing-healthcare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-commons",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "embedded-nutrition",
   "metadata": {},
   "source": [
    "## Define nn.Module\n",
    "\n",
    "class Module:\n",
    "\n",
    "    \"\"\"\n",
    "    Base class for all neural network modules.\n",
    "\n",
    "    Your models should also subclass this class.\n",
    "\n",
    "    Modules can also contain other Modules, allowing to nest them in\n",
    "    a tree structure. You can assign the submodules as regular attributes::\n",
    "\n",
    "        import torch.nn as nn\n",
    "        import torch.nn.functional as F\n",
    "\n",
    "        class Model(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(Model, self).__init__()\n",
    "                self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "                self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "\n",
    "            def forward(self, x):\n",
    "                x = F.relu(self.conv1(x))\n",
    "                return F.relu(self.conv2(x))\n",
    "\n",
    "    Submodules assigned in this way will be registered, and will have their\n",
    "    parameters converted too when you call :meth:`to`, etc.\n",
    "\n",
    "    :ivar training: Boolean represents whether this module is in training or\n",
    "                    evaluation mode.\n",
    "    :vartype training: bool\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "absolute-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 5, 3, bias=True)\n",
    "        self.bn1 = nn.BatchNorm2d(5)\n",
    "        self.conv2 = nn.Conv2d(5, 10, 3, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "detailed-dylan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-mineral",
   "metadata": {},
   "source": [
    "### Debugging model weights interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "spoken-frank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight         - shape: torch.Size([5, 1, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[-0.2852, -0.0701, -0.2741],\n",
      "          [-0.2300,  0.2451,  0.1722],\n",
      "          [ 0.0412, -0.2351, -0.3152]]],\n",
      "\n",
      "\n",
      "        [[[-0.3312, -0.2288,  0.1602],\n",
      "          [-0.2320, -0.2592, -0.1576],\n",
      "          [ 0.3008,  0.2347, -0.3115]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0540,  0.3207, -0.0226],\n",
      "          [-0.2521,  0.0766,  0.2607],\n",
      "          [-0.1463, -0.2773, -0.2015]]],\n",
      "\n",
      "\n",
      "        [[[-0.1584,  0.2522, -0.2695],\n",
      "          [-0.0198,  0.2126,  0.0056],\n",
      "          [ 0.0169,  0.3250,  0.1753]]],\n",
      "\n",
      "\n",
      "        [[[-0.2620, -0.2368, -0.1383],\n",
      "          [-0.1316, -0.2939,  0.2736],\n",
      "          [-0.1345,  0.2951,  0.3140]]]], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "conv1.bias           - shape: torch.Size([5])\n",
      "Parameter containing:\n",
      "tensor([-0.1654, -0.0731, -0.0374, -0.2080,  0.2781], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.weight           - shape: torch.Size([5])\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.bias             - shape: torch.Size([5])\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "conv2.weight         - shape: torch.Size([10, 5, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0934, -0.0934, -0.0431],\n",
      "          [-0.0810, -0.1368, -0.1423],\n",
      "          [ 0.1405, -0.0616,  0.0838]],\n",
      "\n",
      "         [[ 0.0166, -0.1451, -0.0360],\n",
      "          [ 0.0167,  0.0096, -0.0209],\n",
      "          [-0.0254, -0.0955,  0.0357]],\n",
      "\n",
      "         [[ 0.0272,  0.0068, -0.0429],\n",
      "          [-0.0134, -0.0782,  0.0893],\n",
      "          [ 0.0191, -0.1120,  0.1083]],\n",
      "\n",
      "         [[-0.1019,  0.1007,  0.1384],\n",
      "          [ 0.0143,  0.0062,  0.0932],\n",
      "          [ 0.1442, -0.1256,  0.0595]],\n",
      "\n",
      "         [[ 0.1206,  0.1361, -0.0282],\n",
      "          [ 0.0350,  0.0863, -0.0986],\n",
      "          [-0.0319, -0.1344,  0.0964]]],\n",
      "\n",
      "\n",
      "        [[[-0.0716, -0.1446, -0.0929],\n",
      "          [ 0.1304,  0.1380, -0.0310],\n",
      "          [-0.1174,  0.0916, -0.0504]],\n",
      "\n",
      "         [[ 0.1160,  0.1030, -0.1328],\n",
      "          [ 0.1010, -0.1184,  0.0625],\n",
      "          [ 0.0721,  0.0418, -0.0301]],\n",
      "\n",
      "         [[ 0.0035, -0.0043,  0.0708],\n",
      "          [ 0.0652,  0.1111,  0.1357],\n",
      "          [-0.1305, -0.0142, -0.1102]],\n",
      "\n",
      "         [[-0.0651,  0.1077,  0.0171],\n",
      "          [-0.0951,  0.0187,  0.0971],\n",
      "          [ 0.1099,  0.0091, -0.1015]],\n",
      "\n",
      "         [[ 0.1322, -0.0739, -0.0880],\n",
      "          [-0.1232, -0.1114, -0.0380],\n",
      "          [-0.1184, -0.0648,  0.0460]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1281,  0.0667,  0.0127],\n",
      "          [ 0.0567, -0.1395,  0.0822],\n",
      "          [ 0.1313,  0.1063,  0.1239]],\n",
      "\n",
      "         [[-0.0842, -0.1471,  0.0029],\n",
      "          [-0.0088,  0.1198, -0.0594],\n",
      "          [-0.0213, -0.1385,  0.1323]],\n",
      "\n",
      "         [[-0.0351,  0.1210,  0.0603],\n",
      "          [ 0.0902,  0.0168,  0.1270],\n",
      "          [-0.0009,  0.0276,  0.0441]],\n",
      "\n",
      "         [[-0.1174,  0.1283, -0.0328],\n",
      "          [ 0.0890, -0.0960,  0.1293],\n",
      "          [-0.0487, -0.1169, -0.0890]],\n",
      "\n",
      "         [[-0.1401,  0.0099, -0.0305],\n",
      "          [ 0.0244, -0.1150,  0.0319],\n",
      "          [-0.0636, -0.0023,  0.0415]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1051, -0.0712,  0.0258],\n",
      "          [ 0.1203, -0.0162, -0.1292],\n",
      "          [-0.0544, -0.0702,  0.0155]],\n",
      "\n",
      "         [[ 0.0267, -0.1049,  0.0391],\n",
      "          [ 0.1022,  0.0247, -0.0274],\n",
      "          [-0.1160,  0.0137, -0.0017]],\n",
      "\n",
      "         [[-0.1218, -0.0218, -0.1157],\n",
      "          [ 0.1163, -0.0014,  0.1095],\n",
      "          [ 0.1151, -0.0397, -0.0954]],\n",
      "\n",
      "         [[-0.0278, -0.1337,  0.0420],\n",
      "          [-0.1062,  0.0155,  0.0646],\n",
      "          [ 0.1089,  0.0156,  0.0290]],\n",
      "\n",
      "         [[-0.0529, -0.1293, -0.0536],\n",
      "          [-0.0617, -0.0496, -0.1005],\n",
      "          [ 0.1251, -0.0438, -0.0289]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0038, -0.0446,  0.1347],\n",
      "          [ 0.0648,  0.1161,  0.0457],\n",
      "          [-0.1158, -0.1314,  0.1447]],\n",
      "\n",
      "         [[-0.0780,  0.0156,  0.0208],\n",
      "          [-0.1352,  0.1162, -0.1075],\n",
      "          [ 0.0027,  0.0747,  0.0968]],\n",
      "\n",
      "         [[ 0.0963,  0.0787, -0.0920],\n",
      "          [-0.0273, -0.1313,  0.0147],\n",
      "          [ 0.1269, -0.0691,  0.0399]],\n",
      "\n",
      "         [[-0.1038, -0.0433, -0.0076],\n",
      "          [ 0.0218, -0.0597, -0.0822],\n",
      "          [ 0.0857,  0.0418,  0.1235]],\n",
      "\n",
      "         [[ 0.0349,  0.0490,  0.0769],\n",
      "          [ 0.0105, -0.0043, -0.0016],\n",
      "          [-0.0719,  0.0802,  0.1048]]],\n",
      "\n",
      "\n",
      "        [[[-0.1033, -0.1233,  0.0778],\n",
      "          [-0.0817,  0.0406,  0.0427],\n",
      "          [ 0.0834, -0.0483, -0.0777]],\n",
      "\n",
      "         [[ 0.0560,  0.0641, -0.0357],\n",
      "          [ 0.0889, -0.0694,  0.1462],\n",
      "          [-0.1077,  0.0229,  0.1172]],\n",
      "\n",
      "         [[-0.0842, -0.0761, -0.1201],\n",
      "          [ 0.1107,  0.0953,  0.0619],\n",
      "          [ 0.0933,  0.1462, -0.1059]],\n",
      "\n",
      "         [[ 0.0540, -0.0601,  0.0901],\n",
      "          [-0.0584, -0.1151,  0.0349],\n",
      "          [-0.0502, -0.1132, -0.0650]],\n",
      "\n",
      "         [[ 0.0975, -0.0506,  0.0390],\n",
      "          [-0.1289, -0.1349, -0.0186],\n",
      "          [ 0.0952, -0.0478,  0.1316]]],\n",
      "\n",
      "\n",
      "        [[[-0.0959,  0.1407,  0.1131],\n",
      "          [-0.0464, -0.1455,  0.0654],\n",
      "          [ 0.0102, -0.0668, -0.0367]],\n",
      "\n",
      "         [[ 0.0491, -0.0456, -0.1050],\n",
      "          [-0.1437, -0.0308, -0.0659],\n",
      "          [-0.0345, -0.0849,  0.0219]],\n",
      "\n",
      "         [[-0.0531,  0.0964, -0.0594],\n",
      "          [-0.0566,  0.0238,  0.1325],\n",
      "          [ 0.1016,  0.1314, -0.0471]],\n",
      "\n",
      "         [[ 0.0763, -0.0629, -0.0436],\n",
      "          [-0.0441, -0.0924,  0.0898],\n",
      "          [-0.0285,  0.0123, -0.0071]],\n",
      "\n",
      "         [[ 0.1068, -0.0940, -0.0867],\n",
      "          [-0.1027,  0.0257, -0.1091],\n",
      "          [ 0.0397,  0.0295, -0.0132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0200,  0.1216,  0.0566],\n",
      "          [ 0.0687,  0.0337,  0.1380],\n",
      "          [ 0.0631, -0.1036,  0.0442]],\n",
      "\n",
      "         [[-0.0098,  0.1288, -0.0072],\n",
      "          [ 0.1363,  0.1037, -0.1362],\n",
      "          [ 0.0962, -0.0034, -0.1040]],\n",
      "\n",
      "         [[ 0.0827,  0.1099,  0.0429],\n",
      "          [ 0.1486,  0.0261, -0.0285],\n",
      "          [ 0.0046,  0.0165,  0.0122]],\n",
      "\n",
      "         [[ 0.0497, -0.1054,  0.0274],\n",
      "          [-0.0707,  0.1431, -0.1201],\n",
      "          [-0.1029,  0.1359,  0.0633]],\n",
      "\n",
      "         [[-0.1412,  0.0995,  0.0711],\n",
      "          [-0.0374,  0.0019, -0.1158],\n",
      "          [ 0.1415, -0.0278, -0.0264]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1265,  0.0347, -0.0356],\n",
      "          [ 0.0340,  0.1188, -0.0811],\n",
      "          [ 0.0907, -0.1180, -0.1099]],\n",
      "\n",
      "         [[-0.0240, -0.0117, -0.0715],\n",
      "          [ 0.0423, -0.0723, -0.1073],\n",
      "          [ 0.0844, -0.0064,  0.1161]],\n",
      "\n",
      "         [[ 0.0522, -0.1069,  0.0121],\n",
      "          [ 0.0839,  0.0570,  0.0972],\n",
      "          [ 0.0530,  0.0392, -0.1375]],\n",
      "\n",
      "         [[ 0.0060,  0.0216, -0.1460],\n",
      "          [-0.0556, -0.1419, -0.1328],\n",
      "          [-0.0081, -0.0741,  0.0693]],\n",
      "\n",
      "         [[ 0.1288,  0.1305, -0.0858],\n",
      "          [-0.0960,  0.0097, -0.1402],\n",
      "          [ 0.1047, -0.1103, -0.0910]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0983,  0.0289, -0.0488],\n",
      "          [ 0.0661,  0.1140,  0.0023],\n",
      "          [ 0.0483, -0.0402, -0.0034]],\n",
      "\n",
      "         [[-0.1167,  0.1087,  0.1348],\n",
      "          [-0.0830, -0.1092, -0.0269],\n",
      "          [-0.0270, -0.0406, -0.1283]],\n",
      "\n",
      "         [[-0.0370, -0.1368,  0.1121],\n",
      "          [ 0.0386,  0.1186,  0.1142],\n",
      "          [ 0.1119, -0.0363,  0.1061]],\n",
      "\n",
      "         [[-0.0756, -0.1377, -0.0713],\n",
      "          [ 0.0534, -0.1224, -0.0660],\n",
      "          [-0.0010,  0.0716, -0.0089]],\n",
      "\n",
      "         [[-0.0045,  0.0221,  0.0670],\n",
      "          [-0.0342,  0.1344, -0.0372],\n",
      "          [-0.1032,  0.0088,  0.1392]]]], requires_grad=True)\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. using named_parameters()\n",
    "for param, weight in model.named_parameters():\n",
    "    print(f\"{param:20} - shape: {weight.size()}\")\n",
    "    print(weight)\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "turkish-wisdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-0.2852, -0.0701, -0.2741],\n",
      "          [-0.2300,  0.2451,  0.1722],\n",
      "          [ 0.0412, -0.2351, -0.3152]]],\n",
      "\n",
      "\n",
      "        [[[-0.3312, -0.2288,  0.1602],\n",
      "          [-0.2320, -0.2592, -0.1576],\n",
      "          [ 0.3008,  0.2347, -0.3115]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0540,  0.3207, -0.0226],\n",
      "          [-0.2521,  0.0766,  0.2607],\n",
      "          [-0.1463, -0.2773, -0.2015]]],\n",
      "\n",
      "\n",
      "        [[[-0.1584,  0.2522, -0.2695],\n",
      "          [-0.0198,  0.2126,  0.0056],\n",
      "          [ 0.0169,  0.3250,  0.1753]]],\n",
      "\n",
      "\n",
      "        [[[-0.2620, -0.2368, -0.1383],\n",
      "          [-0.1316, -0.2939,  0.2736],\n",
      "          [-0.1345,  0.2951,  0.3140]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1654, -0.0731, -0.0374, -0.2080,  0.2781], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 2. directly access with member variable\n",
    "print(model.conv1.weight)\n",
    "print(model.conv1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-patient",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "impressive-smile",
   "metadata": {},
   "source": [
    "## Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "august-austin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saving success at ./runs/best.pth\n",
      "Saved models : ['best.pth']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "save_folder = \"./runs/\"\n",
    "save_path = os.path.join(save_folder, \"best.pth\")   # ./runs/best.pth\n",
    "os.makedirs(save_folder, exist_ok=True)  \n",
    "\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"Model saving success at {save_path}\")\n",
    "print(f\"Saved models : {os.listdir(save_folder)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-desert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "academic-toolbox",
   "metadata": {},
   "source": [
    "## Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "impressed-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loading success from ./runs/best.pth\n"
     ]
    }
   ],
   "source": [
    "new_model = Model()\n",
    "new_model.load_state_dict(torch.load(save_path))\n",
    "print(f\"Model loading success from {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-moscow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "optional-cylinder",
   "metadata": {},
   "source": [
    "### Check if weights loaded successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "promising-jesus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter conv1.weight    from trained model and loaded model is equal? -> True\n",
      "parameter conv1.bias      from trained model and loaded model is equal? -> True\n",
      "parameter bn1.weight      from trained model and loaded model is equal? -> True\n",
      "parameter bn1.bias        from trained model and loaded model is equal? -> True\n",
      "parameter conv2.weight    from trained model and loaded model is equal? -> True\n"
     ]
    }
   ],
   "source": [
    "for (name, trained_weight), (_, saved_weight) in zip(model.named_parameters(), new_model.named_parameters()):\n",
    "    is_equal = torch.equal(trained_weight, saved_weight)\n",
    "    print(f\"parameter {name:15} from trained model and loaded model is equal? -> {is_equal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-czech",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aging-headline",
   "metadata": {},
   "source": [
    "### What is state_dict()?\n",
    " - Very similar with .named_parameters()\n",
    " - Python dictionary with model parameter(key) and model weights(value)\n",
    " - Type: collections.OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "social-stamp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight         - shape: torch.Size([5, 1, 3, 3])\n",
      "tensor([[[[-0.2852, -0.0701, -0.2741],\n",
      "          [-0.2300,  0.2451,  0.1722],\n",
      "          [ 0.0412, -0.2351, -0.3152]]],\n",
      "\n",
      "\n",
      "        [[[-0.3312, -0.2288,  0.1602],\n",
      "          [-0.2320, -0.2592, -0.1576],\n",
      "          [ 0.3008,  0.2347, -0.3115]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0540,  0.3207, -0.0226],\n",
      "          [-0.2521,  0.0766,  0.2607],\n",
      "          [-0.1463, -0.2773, -0.2015]]],\n",
      "\n",
      "\n",
      "        [[[-0.1584,  0.2522, -0.2695],\n",
      "          [-0.0198,  0.2126,  0.0056],\n",
      "          [ 0.0169,  0.3250,  0.1753]]],\n",
      "\n",
      "\n",
      "        [[[-0.2620, -0.2368, -0.1383],\n",
      "          [-0.1316, -0.2939,  0.2736],\n",
      "          [-0.1345,  0.2951,  0.3140]]]])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "conv1.bias           - shape: torch.Size([5])\n",
      "tensor([-0.1654, -0.0731, -0.0374, -0.2080,  0.2781])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.weight           - shape: torch.Size([5])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.bias             - shape: torch.Size([5])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.running_mean     - shape: torch.Size([5])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.running_var      - shape: torch.Size([5])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "bn1.num_batches_tracked - shape: torch.Size([])\n",
      "tensor(0)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "conv2.weight         - shape: torch.Size([10, 5, 3, 3])\n",
      "tensor([[[[ 0.0934, -0.0934, -0.0431],\n",
      "          [-0.0810, -0.1368, -0.1423],\n",
      "          [ 0.1405, -0.0616,  0.0838]],\n",
      "\n",
      "         [[ 0.0166, -0.1451, -0.0360],\n",
      "          [ 0.0167,  0.0096, -0.0209],\n",
      "          [-0.0254, -0.0955,  0.0357]],\n",
      "\n",
      "         [[ 0.0272,  0.0068, -0.0429],\n",
      "          [-0.0134, -0.0782,  0.0893],\n",
      "          [ 0.0191, -0.1120,  0.1083]],\n",
      "\n",
      "         [[-0.1019,  0.1007,  0.1384],\n",
      "          [ 0.0143,  0.0062,  0.0932],\n",
      "          [ 0.1442, -0.1256,  0.0595]],\n",
      "\n",
      "         [[ 0.1206,  0.1361, -0.0282],\n",
      "          [ 0.0350,  0.0863, -0.0986],\n",
      "          [-0.0319, -0.1344,  0.0964]]],\n",
      "\n",
      "\n",
      "        [[[-0.0716, -0.1446, -0.0929],\n",
      "          [ 0.1304,  0.1380, -0.0310],\n",
      "          [-0.1174,  0.0916, -0.0504]],\n",
      "\n",
      "         [[ 0.1160,  0.1030, -0.1328],\n",
      "          [ 0.1010, -0.1184,  0.0625],\n",
      "          [ 0.0721,  0.0418, -0.0301]],\n",
      "\n",
      "         [[ 0.0035, -0.0043,  0.0708],\n",
      "          [ 0.0652,  0.1111,  0.1357],\n",
      "          [-0.1305, -0.0142, -0.1102]],\n",
      "\n",
      "         [[-0.0651,  0.1077,  0.0171],\n",
      "          [-0.0951,  0.0187,  0.0971],\n",
      "          [ 0.1099,  0.0091, -0.1015]],\n",
      "\n",
      "         [[ 0.1322, -0.0739, -0.0880],\n",
      "          [-0.1232, -0.1114, -0.0380],\n",
      "          [-0.1184, -0.0648,  0.0460]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1281,  0.0667,  0.0127],\n",
      "          [ 0.0567, -0.1395,  0.0822],\n",
      "          [ 0.1313,  0.1063,  0.1239]],\n",
      "\n",
      "         [[-0.0842, -0.1471,  0.0029],\n",
      "          [-0.0088,  0.1198, -0.0594],\n",
      "          [-0.0213, -0.1385,  0.1323]],\n",
      "\n",
      "         [[-0.0351,  0.1210,  0.0603],\n",
      "          [ 0.0902,  0.0168,  0.1270],\n",
      "          [-0.0009,  0.0276,  0.0441]],\n",
      "\n",
      "         [[-0.1174,  0.1283, -0.0328],\n",
      "          [ 0.0890, -0.0960,  0.1293],\n",
      "          [-0.0487, -0.1169, -0.0890]],\n",
      "\n",
      "         [[-0.1401,  0.0099, -0.0305],\n",
      "          [ 0.0244, -0.1150,  0.0319],\n",
      "          [-0.0636, -0.0023,  0.0415]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1051, -0.0712,  0.0258],\n",
      "          [ 0.1203, -0.0162, -0.1292],\n",
      "          [-0.0544, -0.0702,  0.0155]],\n",
      "\n",
      "         [[ 0.0267, -0.1049,  0.0391],\n",
      "          [ 0.1022,  0.0247, -0.0274],\n",
      "          [-0.1160,  0.0137, -0.0017]],\n",
      "\n",
      "         [[-0.1218, -0.0218, -0.1157],\n",
      "          [ 0.1163, -0.0014,  0.1095],\n",
      "          [ 0.1151, -0.0397, -0.0954]],\n",
      "\n",
      "         [[-0.0278, -0.1337,  0.0420],\n",
      "          [-0.1062,  0.0155,  0.0646],\n",
      "          [ 0.1089,  0.0156,  0.0290]],\n",
      "\n",
      "         [[-0.0529, -0.1293, -0.0536],\n",
      "          [-0.0617, -0.0496, -0.1005],\n",
      "          [ 0.1251, -0.0438, -0.0289]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0038, -0.0446,  0.1347],\n",
      "          [ 0.0648,  0.1161,  0.0457],\n",
      "          [-0.1158, -0.1314,  0.1447]],\n",
      "\n",
      "         [[-0.0780,  0.0156,  0.0208],\n",
      "          [-0.1352,  0.1162, -0.1075],\n",
      "          [ 0.0027,  0.0747,  0.0968]],\n",
      "\n",
      "         [[ 0.0963,  0.0787, -0.0920],\n",
      "          [-0.0273, -0.1313,  0.0147],\n",
      "          [ 0.1269, -0.0691,  0.0399]],\n",
      "\n",
      "         [[-0.1038, -0.0433, -0.0076],\n",
      "          [ 0.0218, -0.0597, -0.0822],\n",
      "          [ 0.0857,  0.0418,  0.1235]],\n",
      "\n",
      "         [[ 0.0349,  0.0490,  0.0769],\n",
      "          [ 0.0105, -0.0043, -0.0016],\n",
      "          [-0.0719,  0.0802,  0.1048]]],\n",
      "\n",
      "\n",
      "        [[[-0.1033, -0.1233,  0.0778],\n",
      "          [-0.0817,  0.0406,  0.0427],\n",
      "          [ 0.0834, -0.0483, -0.0777]],\n",
      "\n",
      "         [[ 0.0560,  0.0641, -0.0357],\n",
      "          [ 0.0889, -0.0694,  0.1462],\n",
      "          [-0.1077,  0.0229,  0.1172]],\n",
      "\n",
      "         [[-0.0842, -0.0761, -0.1201],\n",
      "          [ 0.1107,  0.0953,  0.0619],\n",
      "          [ 0.0933,  0.1462, -0.1059]],\n",
      "\n",
      "         [[ 0.0540, -0.0601,  0.0901],\n",
      "          [-0.0584, -0.1151,  0.0349],\n",
      "          [-0.0502, -0.1132, -0.0650]],\n",
      "\n",
      "         [[ 0.0975, -0.0506,  0.0390],\n",
      "          [-0.1289, -0.1349, -0.0186],\n",
      "          [ 0.0952, -0.0478,  0.1316]]],\n",
      "\n",
      "\n",
      "        [[[-0.0959,  0.1407,  0.1131],\n",
      "          [-0.0464, -0.1455,  0.0654],\n",
      "          [ 0.0102, -0.0668, -0.0367]],\n",
      "\n",
      "         [[ 0.0491, -0.0456, -0.1050],\n",
      "          [-0.1437, -0.0308, -0.0659],\n",
      "          [-0.0345, -0.0849,  0.0219]],\n",
      "\n",
      "         [[-0.0531,  0.0964, -0.0594],\n",
      "          [-0.0566,  0.0238,  0.1325],\n",
      "          [ 0.1016,  0.1314, -0.0471]],\n",
      "\n",
      "         [[ 0.0763, -0.0629, -0.0436],\n",
      "          [-0.0441, -0.0924,  0.0898],\n",
      "          [-0.0285,  0.0123, -0.0071]],\n",
      "\n",
      "         [[ 0.1068, -0.0940, -0.0867],\n",
      "          [-0.1027,  0.0257, -0.1091],\n",
      "          [ 0.0397,  0.0295, -0.0132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0200,  0.1216,  0.0566],\n",
      "          [ 0.0687,  0.0337,  0.1380],\n",
      "          [ 0.0631, -0.1036,  0.0442]],\n",
      "\n",
      "         [[-0.0098,  0.1288, -0.0072],\n",
      "          [ 0.1363,  0.1037, -0.1362],\n",
      "          [ 0.0962, -0.0034, -0.1040]],\n",
      "\n",
      "         [[ 0.0827,  0.1099,  0.0429],\n",
      "          [ 0.1486,  0.0261, -0.0285],\n",
      "          [ 0.0046,  0.0165,  0.0122]],\n",
      "\n",
      "         [[ 0.0497, -0.1054,  0.0274],\n",
      "          [-0.0707,  0.1431, -0.1201],\n",
      "          [-0.1029,  0.1359,  0.0633]],\n",
      "\n",
      "         [[-0.1412,  0.0995,  0.0711],\n",
      "          [-0.0374,  0.0019, -0.1158],\n",
      "          [ 0.1415, -0.0278, -0.0264]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1265,  0.0347, -0.0356],\n",
      "          [ 0.0340,  0.1188, -0.0811],\n",
      "          [ 0.0907, -0.1180, -0.1099]],\n",
      "\n",
      "         [[-0.0240, -0.0117, -0.0715],\n",
      "          [ 0.0423, -0.0723, -0.1073],\n",
      "          [ 0.0844, -0.0064,  0.1161]],\n",
      "\n",
      "         [[ 0.0522, -0.1069,  0.0121],\n",
      "          [ 0.0839,  0.0570,  0.0972],\n",
      "          [ 0.0530,  0.0392, -0.1375]],\n",
      "\n",
      "         [[ 0.0060,  0.0216, -0.1460],\n",
      "          [-0.0556, -0.1419, -0.1328],\n",
      "          [-0.0081, -0.0741,  0.0693]],\n",
      "\n",
      "         [[ 0.1288,  0.1305, -0.0858],\n",
      "          [-0.0960,  0.0097, -0.1402],\n",
      "          [ 0.1047, -0.1103, -0.0910]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0983,  0.0289, -0.0488],\n",
      "          [ 0.0661,  0.1140,  0.0023],\n",
      "          [ 0.0483, -0.0402, -0.0034]],\n",
      "\n",
      "         [[-0.1167,  0.1087,  0.1348],\n",
      "          [-0.0830, -0.1092, -0.0269],\n",
      "          [-0.0270, -0.0406, -0.1283]],\n",
      "\n",
      "         [[-0.0370, -0.1368,  0.1121],\n",
      "          [ 0.0386,  0.1186,  0.1142],\n",
      "          [ 0.1119, -0.0363,  0.1061]],\n",
      "\n",
      "         [[-0.0756, -0.1377, -0.0713],\n",
      "          [ 0.0534, -0.1224, -0.0660],\n",
      "          [-0.0010,  0.0716, -0.0089]],\n",
      "\n",
      "         [[-0.0045,  0.0221,  0.0670],\n",
      "          [-0.0342,  0.1344, -0.0372],\n",
      "          [-0.1032,  0.0088,  0.1392]]]])\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for param, weight in model.state_dict().items():\n",
    "    print(f\"{param:20} - shape: {weight.size()}\")\n",
    "    print(weight)\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "handed-stomach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.state_dict() type is : <class 'collections.OrderedDict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "print(f\"model.state_dict() type is : {type(model.state_dict())}\")\n",
    "type(model.state_dict()) == OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "regulation-catalog",
   "metadata": {},
   "source": [
    "### What is difference between named_parameters() and state_dict()?\n",
    " - named_parameters() : returns only parameters\n",
    " - state_dict(): returns both parameters and buffers (e.g. BN runnin_mean, running_var)\n",
    " \n",
    "https://stackoverflow.com/a/54747245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "completed-delaware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1.weight', 'conv1.bias', 'bn1.weight', 'bn1.bias', 'conv2.weight']\n",
      "\n",
      "['conv1.weight',\n",
      " 'conv1.bias',\n",
      " 'bn1.weight',\n",
      " 'bn1.bias',\n",
      " 'bn1.running_mean',\n",
      " 'bn1.running_var',\n",
      " 'bn1.num_batches_tracked',\n",
      " 'conv2.weight']\n"
     ]
    }
   ],
   "source": [
    "pprint([name for (name, param) in model.named_parameters()])  # named_parameters() : returns only parameters\n",
    "print()\n",
    "pprint(list(model.state_dict().keys()))  # state_dict(): retuns both parameters and buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-scheme",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "italic-solid",
   "metadata": {},
   "source": [
    "## CPU vs GPU\n",
    " - When training DL model, different types of processors(CPU, GPU etc) are used.\n",
    " - Therefore, you should assign loading your model's memory to whether CPU or GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-bruce",
   "metadata": {},
   "source": [
    "### cpu()\n",
    "Moves all model parameters and buffers to the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "compound-implementation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n"
     ]
    }
   ],
   "source": [
    "model.cpu()\n",
    "for weight in model.parameters():\n",
    "    print(f\"model device: {weight.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-monster",
   "metadata": {},
   "source": [
    "### cuda()\n",
    "Moves all model parameters and buffers to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "assigned-glasgow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "model.cuda()\n",
    "for weight in model.parameters():\n",
    "    print(f\"model device: {weight.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-oxide",
   "metadata": {},
   "source": [
    "### to()\n",
    "Moves and/or casts the parameters and buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "korean-peace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set model device to cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "model device: cpu\n",
      "\n",
      "Set model device to cuda\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "model device: cuda:0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device_options = ['cpu', 'cuda']\n",
    "for device_option in device_options:\n",
    "    device = torch.device(device_option)\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"Set model device to {device_option}\")\n",
    "    for weight in model.parameters():\n",
    "        print(f\"model device: {weight.device}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-resolution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "reserved-introduction",
   "metadata": {},
   "source": [
    "## Forward\n",
    "Defines the computation performed at every call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "political-dragon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output: torch.Size([1, 10, 24, 24])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.4362, 0.0000,  ..., 0.1937, 0.6275, 0.2357],\n",
       "          [0.3993, 0.0000, 0.0000,  ..., 0.1419, 0.4596, 0.0000],\n",
       "          [0.2169, 0.0000, 0.0000,  ..., 0.0000, 0.2461, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.7581,  ..., 0.4056, 0.0000, 0.0000],\n",
       "          [0.5377, 0.0000, 0.3348,  ..., 0.0000, 0.1200, 0.0665],\n",
       "          [0.0597, 0.3673, 0.0000,  ..., 0.0000, 0.5259, 0.6356]],\n",
       "\n",
       "         [[0.3605, 0.0000, 0.3674,  ..., 0.0000, 0.0000, 0.1606],\n",
       "          [0.1811, 0.0768, 0.0000,  ..., 0.2405, 0.2088, 0.5318],\n",
       "          [0.3466, 0.0000, 0.0000,  ..., 0.0000, 0.0161, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0693, 0.1541,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.5182, 0.4892,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.4361, 0.7166, 0.0000,  ..., 0.5499, 0.1858, 0.0000],\n",
       "          [0.0000, 0.1994, 0.3416,  ..., 0.1077, 0.4668, 0.0000],\n",
       "          [0.7642, 0.2475, 0.0000,  ..., 0.1781, 0.2744, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0248, 0.8703,  ..., 0.5185, 0.3044, 0.0193],\n",
       "          [0.8012, 0.0000, 0.8918,  ..., 0.1307, 0.0000, 0.0000],\n",
       "          [0.3860, 0.1636, 0.7355,  ..., 0.0000, 0.2423, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.2582, 0.4371, 0.3738,  ..., 0.4469, 0.3278, 0.5173],\n",
       "          [0.8134, 0.4756, 0.4901,  ..., 0.2477, 0.2722, 0.7147],\n",
       "          [0.1707, 0.0000, 0.6727,  ..., 0.0000, 0.0140, 0.8671],\n",
       "          ...,\n",
       "          [0.5999, 0.7163, 0.7062,  ..., 0.0953, 0.6144, 0.8024],\n",
       "          [0.9328, 0.6376, 0.6898,  ..., 0.0184, 0.0305, 0.3577],\n",
       "          [0.1448, 0.5151, 0.1322,  ..., 0.1789, 0.0533, 0.0993]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.1613, 0.1374, 0.1331],\n",
       "          [0.2220, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1273],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1340],\n",
       "          [0.4372, 0.3049, 0.3218,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0546, 0.0000, 0.2548,  ..., 0.1875, 0.3736, 0.0210],\n",
       "          [0.2881, 0.4952, 0.0000,  ..., 0.0157, 0.0000, 0.0000],\n",
       "          [0.0000, 0.1173, 0.1683,  ..., 0.4059, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.6543, 0.0000, 0.0886,  ..., 0.3835, 0.0000, 0.0371],\n",
       "          [0.1170, 0.2810, 0.1389,  ..., 0.5320, 0.1530, 0.0000],\n",
       "          [0.0183, 0.0000, 0.0000,  ..., 0.0000, 0.2710, 0.0000]]]],\n",
       "       device='cuda:0', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "output = model(dummy_input)\n",
    "print(f\"model output: {output.size()}\")\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-peninsula",
   "metadata": {},
   "source": [
    "### Tips\n",
    "Model's device and Inputs'device must be identical, otherwise runtime Exception raised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "utility-professor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model output: torch.Size([1, 10, 24, 24])\n"
     ]
    }
   ],
   "source": [
    "cpu_device = torch.device('cpu')\n",
    "gpu_device = torch.device('cuda')\n",
    "\n",
    "# device is same\n",
    "dummy_input = dummy_input.to(gpu_device)\n",
    "model.to(gpu_device)\n",
    "output = model(dummy_input)\n",
    "print(f\"model output: {output.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "desperate-tulsa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-158d23f8876d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# device is different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"model output: {output.size()}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-5bbe30af4ab4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/torch1.7/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _thnn_conv2d_forward"
     ]
    }
   ],
   "source": [
    "dummy_input = dummy_input.to(cpu_device)\n",
    "model.to(gpu_device)\n",
    "\n",
    "# device is different\n",
    "# RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same\n",
    "output = model(dummy_input)  \n",
    "print(f\"model output: {output.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-exclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "operational-american",
   "metadata": {},
   "source": [
    "### requires_grad()\n",
    "Change if autograd should record operations on parameters in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "supposed-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param conv1.weight    required gradient? -> False\n",
      "param conv1.bias      required gradient? -> False\n",
      "param bn1.weight      required gradient? -> False\n",
      "param bn1.bias        required gradient? -> False\n",
      "param conv2.weight    required gradient? -> False\n"
     ]
    }
   ],
   "source": [
    "# requires_grad = False\n",
    "model.requires_grad_(requires_grad=False)\n",
    "for param, weight in model.named_parameters():\n",
    "    print(f\"param {param:15} required gradient? -> {weight.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "absent-strip",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param conv1.weight    required gradient? -> True\n",
      "param conv1.bias      required gradient? -> True\n",
      "param bn1.weight      required gradient? -> True\n",
      "param bn1.bias        required gradient? -> True\n",
      "param conv2.weight    required gradient? -> True\n"
     ]
    }
   ],
   "source": [
    "# requires_grad = True\n",
    "model.requires_grad_(requires_grad=True)\n",
    "for param, weight in model.named_parameters():\n",
    "    print(f\"param {param:15} required gradient? -> {weight.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-fight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-aspect",
   "metadata": {},
   "source": [
    "### train(), eval()\n",
    "Sets the module in training(evaluation) mode.\n",
    "\n",
    "This has effects only on certain modules which works differently in training/evaluation\n",
    "such as Dropout or BatchNorm\n",
    "\n",
    "You should set model to train mode if your are on training phase, otherwise eval model\n",
    "\n",
    "[Below is pytorch implementation of BatchNorm2d](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/batchnorm.py#L111-L118).\n",
    "Check that tracking running_mean, running_var only when `self.training=True`\n",
    "```\n",
    "if self.training and self.track_running_stats:\n",
    "    # TODO: if statement only here to tell the jit to skip emitting this when it is None\n",
    "    if self.num_batches_tracked is not None:\n",
    "        self.num_batches_tracked = self.num_batches_tracked + 1\n",
    "        if self.momentum is None:  # use cumulative moving average\n",
    "            exponential_average_factor = 1.0 / float(self.num_batches_tracked)\n",
    "        else:  # use exponential moving average\n",
    "            exponential_average_factor = self.momentum\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "nonprofit-lotus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.bn1.training: True\n"
     ]
    }
   ],
   "source": [
    "model.train()  # set model to train mode\n",
    "print(f\"model.bn1.training: {model.bn1.training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "worse-issue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.bn1.training: False\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # set model to eval mode\n",
    "print(f\"model.bn1.training: {model.bn1.training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-leader",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "latter-webster",
   "metadata": {},
   "source": [
    "### You can check more details about nn.Module at pytorch official documentation\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n",
    "\n",
    "It is highly recommended to check official documentation if you have any question about pyTorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
